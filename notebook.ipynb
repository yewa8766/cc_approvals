{"cells":[{"source":"![Credit card being held in hand](credit_card.jpg)\n\nCommercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n\n### The Data\n\nThe data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.","metadata":{},"id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1758268509117,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","outputsMetadata":{"0":{"height":0,"type":"dataFrame","tableState":{}}},"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5"},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"0","type":"string"},{"name":"1","type":"string"},{"name":"2","type":"number"},{"name":"3","type":"string"},{"name":"4","type":"string"},{"name":"5","type":"string"},{"name":"6","type":"string"},{"name":"7","type":"number"},{"name":"8","type":"string"},{"name":"9","type":"string"},{"name":"10","type":"integer"},{"name":"11","type":"string"},{"name":"12","type":"integer"},{"name":"13","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":["b","a","a","b","b"],"1":["30.83","58.67","24.50","27.83","20.17"],"2":[0,4.46,0.5,1.54,5.625],"3":["u","u","u","u","u"],"4":["g","g","g","g","g"],"5":["w","q","q","w","w"],"6":["v","h","h","v","v"],"7":[1.25,3.04,1.5,3.75,1.71],"8":["t","t","t","t","t"],"9":["t","t","f","t","f"],"10":[1,6,0,5,0],"11":["g","g","g","g","s"],"12":[0,560,824,3,0],"13":["+","+","+","+","+"],"index":[0,1,2,3,4]}},"total_rows":5,"truncation_type":null},"text/plain":"  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>g</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>g</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>g</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>g</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>s</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":26}]},{"source":"# Show the indices of rows that contain \"?\" in any column\ncc_apps[cc_apps.isin(['?']).any(axis=1)].index\n## Index([ 83,  86,  92,  97, 206, 248, 254, 270, 286, 327, 329, 330, 346,\n##         374, 445, 450, 453, 456, 479, 489, 500, 515, 520, 539, 592, 598,\n##         601, 608, 622, 641, 673]) contains '?'\n\n# Replace the '?'s with NaN in dataset\ncc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\ncc_apps_nans_replaced.head()","metadata":{"executionCancelledAt":null,"executionTime":66,"lastExecutedAt":1758268509183,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Show the indices of rows that contain \"?\" in any column\ncc_apps[cc_apps.isin(['?']).any(axis=1)].index\n## Index([ 83,  86,  92,  97, 206, 248, 254, 270, 286, 327, 329, 330, 346,\n##         374, 445, 450, 453, 456, 479, 489, 500, 515, 520, 539, 592, 598,\n##         601, 608, 622, 641, 673]) contains '?'\n\n# Replace the '?'s with NaN in dataset\ncc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\ncc_apps_nans_replaced.head()","outputsMetadata":{"0":{"height":0,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"00ccdf0b-083d-4604-80a5-45c2137a2725","nodeType":"const"}}}}},"cell_type":"code","id":"99a1badc-3e67-4bbf-8629-381f36b0a1f7","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"0","type":"string"},{"name":"1","type":"string"},{"name":"2","type":"number"},{"name":"3","type":"string"},{"name":"4","type":"string"},{"name":"5","type":"string"},{"name":"6","type":"string"},{"name":"7","type":"number"},{"name":"8","type":"string"},{"name":"9","type":"string"},{"name":"10","type":"integer"},{"name":"11","type":"string"},{"name":"12","type":"integer"},{"name":"13","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":["b","a","a","b","b"],"1":["30.83","58.67","24.50","27.83","20.17"],"2":[0,4.46,0.5,1.54,5.625],"3":["u","u","u","u","u"],"4":["g","g","g","g","g"],"5":["w","q","q","w","w"],"6":["v","h","h","v","v"],"7":[1.25,3.04,1.5,3.75,1.71],"8":["t","t","t","t","t"],"9":["t","t","f","t","f"],"10":[1,6,0,5,0],"11":["g","g","g","g","s"],"12":[0,560,824,3,0],"13":["+","+","+","+","+"],"index":[0,1,2,3,4]}},"total_rows":5,"truncation_type":null},"text/plain":"  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>g</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>g</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>g</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>g</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>s</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":27}],"execution_count":27},{"source":"# Create a copy of the NaN replacement DataFrame\ncc_apps_imputed = cc_apps_nans_replaced.copy()\n\n# Iterate over each column of cc_apps_nans_replaced \n# and impute the most frequent value for object data types and the mean for numeric data types\nfor col in cc_apps_imputed.columns:\n    # Check if the column is of object type\n    if cc_apps_imputed[col].dtypes == \"object\":\n        # Impute with the most frequent value\n        print(str(col))\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n            cc_apps_imputed[col].value_counts().index[0]\n        )\n        print('impute with the most frequent value ' + str(cc_apps_imputed[col].value_counts().index[0]))\n    else:\n        print(str(col))\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n        print('impute with the mean value ' + str(cc_apps_imputed[col].mean()))\n","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1758268509233,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a copy of the NaN replacement DataFrame\ncc_apps_imputed = cc_apps_nans_replaced.copy()\n\n# Iterate over each column of cc_apps_nans_replaced \n# and impute the most frequent value for object data types and the mean for numeric data types\nfor col in cc_apps_imputed.columns:\n    # Check if the column is of object type\n    if cc_apps_imputed[col].dtypes == \"object\":\n        # Impute with the most frequent value\n        print(str(col))\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n            cc_apps_imputed[col].value_counts().index[0]\n        )\n        print('impute with the most frequent value ' + str(cc_apps_imputed[col].value_counts().index[0]))\n    else:\n        print(str(col))\n        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n        print('impute with the mean value ' + str(cc_apps_imputed[col].mean()))\n","outputsMetadata":{"0":{"height":0,"type":"stream"}}},"cell_type":"code","id":"c16117a4-1a18-49c4-81d3-b1d4aac53670","outputs":[{"output_type":"stream","name":"stdout","text":"0\nimpute with the most frequent value b\n1\nimpute with the most frequent value 22.67\n2\nimpute with the mean value 4.758724637681159\n3\nimpute with the most frequent value u\n4\nimpute with the most frequent value g\n5\nimpute with the most frequent value c\n6\nimpute with the most frequent value v\n7\nimpute with the mean value 2.223405797101449\n8\nimpute with the most frequent value t\n9\nimpute with the most frequent value f\n10\nimpute with the mean value 2.4\n11\nimpute with the most frequent value g\n12\nimpute with the mean value 1017.3855072463768\n13\nimpute with the most frequent value -\n"}],"execution_count":28},{"source":"# Dummify the categorical features\ncc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)\n","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1758268509281,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Dummify the categorical features\ncc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)\n","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"00ccdf0b-083d-4604-80a5-45c2137a2725","nodeType":"const"}}}}},"cell_type":"code","id":"b80007e3-40da-4483-acde-af8c2efcd8b6","outputs":[],"execution_count":29},{"source":"# Extract the last column as your target variable\nX = cc_apps_encoded.iloc[:, :-1].values\ny = cc_apps_encoded.iloc[:, [-1]].values\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1758268509333,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extract the last column as your target variable\nX = cc_apps_encoded.iloc[:, :-1].values\ny = cc_apps_encoded.iloc[:, [-1]].values\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"},"cell_type":"code","id":"8dcdbfc5-502a-477f-ad79-50eaf297c397","outputs":[],"execution_count":30},{"source":"# Instantiate StandardScaler and use it to rescale X_train and X_test\nscaler = StandardScaler()\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.transform(X_test)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1758268509389,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate StandardScaler and use it to rescale X_train and X_test\nscaler = StandardScaler()\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.transform(X_test)"},"cell_type":"code","id":"43e3dc6c-9ea3-4c44-b5d4-b1ec1803f53a","outputs":[],"execution_count":31},{"source":"# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n# Fit logreg to the train set\nlogreg.fit(rescaledX_train, y_train)\n\n# Use logreg to predict instances from the training set\ny_train_pred = logreg.predict(rescaledX_train)\n\n# Print the confusion matrix of the logreg model\nprint(confusion_matrix(y_train, y_train_pred))","metadata":{"executionCancelledAt":null,"executionTime":293,"lastExecutedAt":1758268509683,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n# Fit logreg to the train set\nlogreg.fit(rescaledX_train, y_train)\n\n# Use logreg to predict instances from the training set\ny_train_pred = logreg.predict(rescaledX_train)\n\n# Print the confusion matrix of the logreg model\nprint(confusion_matrix(y_train, y_train_pred))","outputsMetadata":{"0":{"height":0,"type":"stream"}}},"cell_type":"code","id":"442a5980-5077-4dd5-9f20-cd5c7d8e325c","outputs":[{"output_type":"stream","name":"stdout","text":"[[203   1]\n [  1 257]]\n"}],"execution_count":32},{"source":"# Define the grid of values for tol and max_iter\ntol = [0.01, 0.001, 0.0001]\nmax_iter = [100, 150, 200]\n\n# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\nparam_grid = dict(tol=tol, max_iter=max_iter)\n\n# Instantiate GridSearchCV with the required parameters\ngrid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n\n# Fit grid_model to the data\ngrid_model_result = grid_model.fit(rescaledX_train, y_train)\n","metadata":{"executionCancelledAt":null,"executionTime":7308,"lastExecutedAt":1758268516991,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the grid of values for tol and max_iter\ntol = [0.01, 0.001, 0.0001]\nmax_iter = [100, 150, 200]\n\n# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\nparam_grid = dict(tol=tol, max_iter=max_iter)\n\n# Instantiate GridSearchCV with the required parameters\ngrid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n\n# Fit grid_model to the data\ngrid_model_result = grid_model.fit(rescaledX_train, y_train)\n"},"cell_type":"code","id":"7bea6bd4-9be9-4315-a636-152724e6fa8c","outputs":[],"execution_count":33},{"source":"# Summarize results\nbest_train_score, best_train_params = grid_model_result.best_score_, grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_train_score, best_train_params))\n","metadata":{"executionCancelledAt":null,"executionTime":104,"lastExecutedAt":1758268517096,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Summarize results\nbest_train_score, best_train_params = grid_model_result.best_score_, grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_train_score, best_train_params))\n","outputsMetadata":{"0":{"height":0,"type":"stream"}}},"cell_type":"code","id":"9427ee1d-e244-4e05-84ca-b4684495fdd3","outputs":[{"output_type":"stream","name":"stdout","text":"Best: 0.818163 using {'max_iter': 100, 'tol': 0.01}\n"}],"execution_count":34},{"source":"# Extract the best model and evaluate it on the test set\nbest_model = grid_model_result.best_estimator_\nbest_score =  best_model.score(rescaledX_test, y_test)\n\nprint(\"Accuracy of logistic regression classifier: \", best_score)","metadata":{"executionCancelledAt":null,"executionTime":90,"lastExecutedAt":1758268517186,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extract the best model and evaluate it on the test set\nbest_model = grid_model_result.best_estimator_\nbest_score =  best_model.score(rescaledX_test, y_test)\n\nprint(\"Accuracy of logistic regression classifier: \", best_score)","outputsMetadata":{"0":{"height":0,"type":"stream"}}},"cell_type":"code","id":"8d7a4f59-c375-4625-88a3-13ef78e875cc","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy of logistic regression classifier:  0.793859649122807\n"}],"execution_count":35},{"source":"from sklearn.metrics import classification_report, confusion_matrix\ny_test_pred = best_model.predict(rescaledX_test)\nprint(confusion_matrix(y_test, y_test_pred))\nprint(classification_report(y_test, y_test_pred))","metadata":{"executionCancelledAt":null,"executionTime":141,"lastExecutedAt":1758269040081,"lastExecutedByKernel":"a92ebc28-bc15-4775-ae44-644ef89afab5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import classification_report, confusion_matrix\ny_test_pred = best_model.predict(rescaledX_test)\nprint(confusion_matrix(y_test, y_test_pred))\nprint(classification_report(y_test, y_test_pred))"},"cell_type":"code","id":"ccde83a8-0ea9-4cb2-bee5-05de20b4ca90","outputs":[{"output_type":"stream","name":"stdout","text":"[[ 81  22]\n [ 25 100]]\n              precision    recall  f1-score   support\n\n           0       0.76      0.79      0.78       103\n           1       0.82      0.80      0.81       125\n\n    accuracy                           0.79       228\n   macro avg       0.79      0.79      0.79       228\nweighted avg       0.79      0.79      0.79       228\n\n"}],"execution_count":37}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}